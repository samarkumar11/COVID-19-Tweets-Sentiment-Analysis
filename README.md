# COVID-19-Tweets-Sentiment-Analysis

This project performs sentiment analysis on a dataset of tweets related to COVID-19 using the Hugging Face Transformers library. The goal is to classify the sentiment of each tweet as positive or negative.

## Project Overview

The project involves the following steps:

1.  **Data Loading:** Loading the dataset of COVID-19 tweets from a CSV file.
2.  **Text Cleaning:** Preprocessing the tweet text by removing special characters, stopwords, and applying lemmatization to prepare it for sentiment analysis.
3.  **Sentiment Analysis:** Utilizing a pre-trained sentiment analysis model from the Hugging Face Transformers library to predict the sentiment of each cleaned tweet.
4.  **Results Output:** Saving the original tweets, cleaned text, predicted sentiment labels, and sentiment scores to a new CSV file.

## Files in this Repository

*   `Corona_NLP_test.csv`: The original dataset containing the tweets.
*   `sentiment_output.csv`: The output file generated by the analysis, including the sentiment predictions.
*   `your_notebook_name.ipynb`: The Google Colab notebook containing the Python code for this project. (Replace `your_notebook_name.ipynb` with the actual name of your notebook file)

## Requirements

To run this notebook and replicate the analysis, you will need to have the following libraries installed:

*   `transformers`
*   `datasets`
*   `sentencepiece`
*   `nltk`
*   `pandas`
*   `torch`

You can install these using pip:

```bash
pip install transformers datasets sentencepiece nltk pandas torch
You will also need to download NLTK data by running the following commands in your Python environment:

import nltk
nltk.download("stopwords")
nltk.download("wordnet")
nltk.download("punkt")
nltk.download("punkt_tab")
Usage
Clone this repository to your local machine or open the notebook in Google Colab.
Make sure you have the required libraries and NLTK data downloaded.
Run the cells in the notebook sequentially.
The output file sentiment_output.csv will be generated in the same directory as the notebook.
Code Explanation
The notebook includes code for:

Loading the data using pandas.
Defining and applying text cleaning functions using Hugging Face tokenizer and NLTK.
Loading the sentiment analysis pipeline from Hugging Face.
Applying the sentiment analysis model to the cleaned text.
Adding the sentiment predictions to the DataFrame.
Saving the results to a CSV file.
Contributing
If you would like to contribute to this project, feel free to fork the repository and submit a pull request.
